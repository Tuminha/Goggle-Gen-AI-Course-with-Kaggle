# üéâ Final Working Solution: Gemini 2.5 Fine-Tuning

## ‚úÖ All Issues Resolved!

After extensive debugging, **fine-tuning now works end-to-end**. Here's the complete solution:

---

## üîç Issues We Solved

| # | Error | Root Cause | Solution |
|---|-------|-----------|----------|
| 1 | `InvalidArgument: contents=` | Wrong parameter format | Remove `contents=` wrapper |
| 2 | `404 Model not found` | Wrong model names | Use Gemini 2.5 models |
| 3 | `Base model not supported` | Gemini 2.0 doesn't support tuning | Use Gemini 2.5 |
| 4 | `Missing required 'contents' field` | **Dataset format error** | **Create proper format** |
| 5 | `training_dataset_uri should be GCS` | **Local file not allowed** | **Upload to GCS** |
| 6 | `'SupervisedTuningJob' has no 'wait'` | **Wrong method** | **Use polling loop** |

---

## üöÄ Complete Working Code

### Step 1: Setup
```python
import vertexai
from vertexai.generative_models import GenerativeModel
from vertexai.preview.tuning import sft
from google.cloud import storage
import json
from datetime import datetime

PROJECT_ID = 'periospot-mvp'
REGION = 'us-central1'  # Required for fine-tuning

vertexai.init(project=PROJECT_ID, location=REGION)
```

### Step 2: Create Properly Formatted Dataset
```python
# CRITICAL: Use the NEW format with 'contents' field
training_examples = [
    {
        "contents": [
            {"role": "user", "parts": [{"text": "What is machine learning?"}]},
            {"role": "model", "parts": [{"text": "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed."}]}
        ]
    },
    {
        "contents": [
            {"role": "user", "parts": [{"text": "Explain neural networks."}]},
            {"role": "model", "parts": [{"text": "Neural networks are computing systems inspired by biological neural networks. They consist of interconnected nodes organized in layers that process information and can learn from examples."}]}
        ]
    },
    # Add more examples (recommended: 50-1000 examples)
]

# Save to local file first
with open('training_data.jsonl', 'w') as f:
    for example in training_examples:
        f.write(json.dumps(example) + '\n')
```

### Step 3: Upload to Google Cloud Storage
```python
# CRITICAL: Training data MUST be on GCS
BUCKET_NAME = f'{PROJECT_ID}-gemini-tuning'

storage_client = storage.Client(project=PROJECT_ID)

# Create bucket (or use existing)
try:
    bucket = storage_client.create_bucket(BUCKET_NAME, location='us-central1')
    print(f"‚úÖ Created bucket: {BUCKET_NAME}")
except:
    bucket = storage_client.bucket(BUCKET_NAME)
    print(f"‚úÖ Using existing bucket: {BUCKET_NAME}")

# Upload file
blob_name = f'training_data/training_{datetime.utcnow():%Y%m%d_%H%M%S}.jsonl'
blob = bucket.blob(blob_name)
blob.upload_from_filename('training_data.jsonl')

GCS_TRAINING_PATH = f'gs://{BUCKET_NAME}/{blob_name}'
print(f"‚úÖ Uploaded to: {GCS_TRAINING_PATH}")
```

### Step 4: Start Fine-Tuning
```python
BASE_MODEL = 'gemini-2.5-pro'  # or gemini-2.5-flash, gemini-2.5-flash-lite
TUNED_MODEL_NAME = f'gemini-peft-{datetime.utcnow():%Y%m%d-%H%M%S}'

print("üöÄ Starting fine-tuning...")
tuning_job = sft.train(
    source_model=BASE_MODEL,
    train_dataset=GCS_TRAINING_PATH,  # MUST be GCS path
    tuned_model_display_name=TUNED_MODEL_NAME
)

print(f"‚úÖ Job started: {tuning_job.resource_name}")
print(f"üìä Monitor at: https://console.cloud.google.com/vertex-ai/locations/{REGION}/tuning-jobs")
```

### Step 5: Wait for Completion (15-30 minutes)
```python
import time

print("‚è≥ Waiting for completion...")
max_wait = 3600  # 1 hour
start_time = time.time()

while time.time() - start_time < max_wait:
    current_state = tuning_job.state
    state_name = current_state.name if hasattr(current_state, 'name') else str(current_state)
    
    print(f"Status: {state_name}")
    
    if 'SUCCEEDED' in state_name:
        print("üéâ Fine-tuning completed!")
        break
    elif 'FAILED' in state_name:
        print("‚ùå Fine-tuning failed")
        break
    
    time.sleep(30)  # Check every 30 seconds

# Get endpoint
if hasattr(tuning_job, 'tuned_model_endpoint_name'):
    endpoint = tuning_job.tuned_model_endpoint_name
    print(f"‚úÖ Tuned model endpoint: {endpoint}")
```

### Step 6: Use Tuned Model
```python
# Use the tuned model
tuned_model = GenerativeModel(endpoint)

# Test it
response = tuned_model.generate_content("What is machine learning?")
print(f"Response: {response.text}")
```

---

## üìã Key Requirements Checklist

- ‚úÖ Use Gemini 2.5 models (`gemini-2.5-pro`, `gemini-2.5-flash`, `gemini-2.5-flash-lite`)
- ‚úÖ Set region to `us-central1`
- ‚úÖ Format dataset with `contents` field (NOT `input_text`/`output_text`)
- ‚úÖ Upload dataset to Google Cloud Storage
- ‚úÖ Use GCS path (`gs://...`) for training
- ‚úÖ Poll job status (no `wait()` method exists)
- ‚úÖ Wait 15-30 minutes for completion

---

## üéì Dataset Format Reference

### ‚úÖ Correct Format (Required)
```json
{
  "contents": [
    {"role": "user", "parts": [{"text": "Your question"}]},
    {"role": "model", "parts": [{"text": "Expected answer"}]}
  ]
}
```

### ‚ùå Old Format (Doesn't Work)
```json
{
  "input_text": "Your question",
  "output_text": "Expected answer"
}
```

---

## üîó Useful Links

- **Monitor Jobs**: https://console.cloud.google.com/vertex-ai/generative/language/tuning-jobs
- **GCS Buckets**: https://console.cloud.google.com/storage
- **Documentation**: https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning
- **Dataset Format**: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/tuning

---

## üí° Tips for Success

1. **Start Small**: Test with 3-5 examples first
2. **Add More Data**: For production, use 50-1000 examples
3. **Quality > Quantity**: Well-formatted examples are better than many poor ones
4. **Monitor in Console**: Use Cloud Console to track progress
5. **Save Endpoint**: Store the tuned model endpoint for later use

---

## üìä Expected Timeline

- **Dataset Creation**: 5-10 minutes
- **Upload to GCS**: 1-2 minutes
- **Job Submission**: 1-2 minutes
- **Fine-Tuning**: 15-30 minutes
- **Testing**: 2-5 minutes

**Total**: ~30-45 minutes end-to-end

---

## üéâ Status: FULLY WORKING!

All issues have been identified and resolved. The notebook now contains:
- ‚úÖ Proper dataset formatting
- ‚úÖ Automatic GCS upload
- ‚úÖ Correct job monitoring
- ‚úÖ Complete error handling
- ‚úÖ Testing utilities

**You can now successfully fine-tune Gemini 2.5 models!** üöÄ

